{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNoASoPYa6GshFYwAT8TJdI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Importing the dependencies"],"metadata":{"id":"kBx4H240ZOxC"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"AGx_8clqZPn3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Device Configuration"],"metadata":{"id":"5tFOTZfbZhKK"}},{"cell_type":"code","source":["# Make device agnostic code\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"WO22P_ARZiG1","executionInfo":{"status":"ok","timestamp":1721276130904,"user_tz":-330,"elapsed":105,"user":{"displayName":"Satheesh Palanisamy","userId":"05467039449028314876"}},"outputId":"aca996ed-00b9-43a3-a4dc-090d0edda445"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["Data Collection and Preprocessing"],"metadata":{"id":"EHz4cqvHZpvV"}},{"cell_type":"code","source":["data=load_breast_cancer()\n","X=data.data\n","Y=data.target"],"metadata":{"id":"lXeFOkK4Z06_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhuY2lyIaRkQ","executionInfo":{"status":"ok","timestamp":1721276130906,"user_tz":-330,"elapsed":97,"user":{"displayName":"Satheesh Palanisamy","userId":"05467039449028314876"}},"outputId":"032fd3e5-cf6a-49e2-e037-292554a9fbe1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n","        1.189e-01],\n","       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n","        8.902e-02],\n","       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n","        8.758e-02],\n","       ...,\n","       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n","        7.820e-02],\n","       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n","        1.240e-01],\n","       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n","        7.039e-02]])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["Y[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-OYHRWk1aVjC","executionInfo":{"status":"ok","timestamp":1721276130907,"user_tz":-330,"elapsed":89,"user":{"displayName":"Satheesh Palanisamy","userId":"05467039449028314876"}},"outputId":"0773ee21-346f-4c57-ae30-b8092bff5267"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0])"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["\n","Splitting the data into Training and Test datasets"],"metadata":{"id":"frBTAGrRaYZe"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","print(X.shape)\n","print (X_train.shape)\n","print (X_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mEKbsiMJaZXl","executionInfo":{"status":"ok","timestamp":1721276130910,"user_tz":-330,"elapsed":87,"user":{"displayName":"Satheesh Palanisamy","userId":"05467039449028314876"}},"outputId":"50e0d837-e980-4be3-f562-8ca401d8bdcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(569, 30)\n","(455, 30)\n","(114, 30)\n"]}]},{"cell_type":"code","source":["# standardize the data using standardscaler\n","scaler=StandardScaler()\n","X_train=scaler.fit_transform(X_train)\n","X_test=scaler.fit_transform(X_test)"],"metadata":{"id":"t9pnUTI0aeLB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Anmt0ZAPahJn","executionInfo":{"status":"ok","timestamp":1721276130912,"user_tz":-330,"elapsed":82,"user":{"displayName":"Satheesh Palanisamy","userId":"05467039449028314876"}},"outputId":"ac827f51-4f67-4fda-9b34-7fc6b21f3e56"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["# convert data to pytorch tensors and move into gpu\n","X_train=torch.tensor(X_train,dtype=torch.float32).to(device)\n","X_test=torch.tensor(X_test,dtype=torch.float32).to(device)\n","y_train=torch.tensor(y_train,dtype=torch.float32).to(device)\n","y_test=torch.tensor(y_test,dtype=torch.float32).to(device)"],"metadata":{"id":"0yIltkgRakV7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Neural Network Architecture"],"metadata":{"id":"y4Jeg49tapCG"}},{"cell_type":"code","source":["# 1. Construct a model class that subclasses nn.Module\n","from torch import nn\n","\n","# Build model\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_features, output_features, hidden_units):\n","        super().__init__()\n","        self.linear_layer_stack = nn.Sequential(\n","            nn.Linear(in_features=input_features, out_features=hidden_units),\n","            nn.ReLU(),\n","            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n","            nn.ReLU(),\n","            nn.Linear(in_features=hidden_units, out_features=output_features), # how many classes are there?\n","        )\n","\n","    def forward(self, x):\n","        return self.linear_layer_stack(x)\n","\n"],"metadata":{"id":"v3BmyacOarBA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model = NeuralNet(input_features=X_train.shape[1],\n","                    output_features=1,\n","                    hidden_units=64).to(device)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lSSEimlniSXb","executionInfo":{"status":"ok","timestamp":1721276130924,"user_tz":-330,"elapsed":84,"user":{"displayName":"Satheesh Palanisamy","userId":"05467039449028314876"}},"outputId":"a62bec97-9bf5-4fc2-9d06-a104d61f89cb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NeuralNet(\n","  (linear_layer_stack): Sequential(\n","    (0): Linear(in_features=30, out_features=64, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=64, out_features=64, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=64, out_features=1, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["X_train.shape[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWQBhMa6i-BN","executionInfo":{"status":"ok","timestamp":1721276130929,"user_tz":-330,"elapsed":83,"user":{"displayName":"Satheesh Palanisamy","userId":"05467039449028314876"}},"outputId":"3c0b0e40-b5a3-471e-c106-0ccbe4be0315"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# Make predictions with the model\n","untrained_preds = model(X_test.to(device))\n","print(f\"Length of predictions: {len(untrained_preds)}, Shape: {untrained_preds.shape}\")\n","print(f\"Length of test samples: {len(y_test)}, Shape: {y_test.shape}\")\n","print(f\"\\nFirst 10 predictions:\\n{untrained_preds[:10]}\")\n","print(f\"\\nFirst 10 test labels:\\n{y_test[:10]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGBNUhtW0ga0","executionInfo":{"status":"ok","timestamp":1721276130930,"user_tz":-330,"elapsed":79,"user":{"displayName":"Satheesh Palanisamy","userId":"05467039449028314876"}},"outputId":"de3e7aa7-546b-42d8-a962-5bca0ac9c8e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of predictions: 114, Shape: torch.Size([114, 1])\n","Length of test samples: 114, Shape: torch.Size([114])\n","\n","First 10 predictions:\n","tensor([[-0.0703],\n","        [ 0.0441],\n","        [-0.0034],\n","        [-0.0384],\n","        [-0.0043],\n","        [ 0.0754],\n","        [ 0.0044],\n","        [-0.0212],\n","        [-0.0342],\n","        [-0.1310]], device='cuda:0', grad_fn=<SliceBackward0>)\n","\n","First 10 test labels:\n","tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 1.], device='cuda:0')\n"]}]},{"cell_type":"markdown","source":["The number of predictions matches the number of test labels, but their shapes or formats are different. We need to change the predictions to match the test labels."],"metadata":{"id":"tjtcpfyb2XNa"}},{"cell_type":"markdown","source":["** Setup loss function and optimizer**"],"metadata":{"id":"gYm8LLDI2ugI"}},{"cell_type":"code","source":["# Create a loss function\n","# loss_fn = nn.BCELoss() # BCELoss = no sigmoid built-in\n","loss_fn = nn.BCEWithLogitsLoss() # BCEWithLogitsLoss = sigmoid built-in\n","\n","# Create an optimizer\n","optimizer = torch.optim.SGD(params=model.parameters(),\n","                            lr=0.1)"],"metadata":{"id":"8b14D7BQ23fk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate accuracy (a classification metric)\n","def accuracy_fn(y_true, y_pred):\n","    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n","    acc = (correct / len(y_pred)) * 100\n","    return acc"],"metadata":{"id":"aSdwqxSb2yAy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Building a training and testing loop"],"metadata":{"id":"_9gFsbst5nGJ"}},{"cell_type":"code","source":["torch.manual_seed(42)\n","epochs = 100\n","\n","# Put data to target device\n","X_train, y_train = X_train.to(device), y_train.to(device)\n","X_test, y_test = X_test.to(device), y_test.to(device)\n","\n","# Build training and evaluation loop\n","for epoch in range(epochs):\n","    ### Training\n","    model.train()\n","\n","    # 1. Forward pass (model outputs raw logits)same device\n","    y_logits = model(X_train).squeeze() # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device\n","    y_pred = torch.round(torch.sigmoid(y_logits))\n","\n","    # 2. Calculate loss/accuracy\n","    # loss = loss_fn(torch.sigmoid(y_logits), # Using nn.BCELoss you need torch.sigmoid()\n","    #                y_train)\n","    loss = loss_fn(y_logits, # Using nn.BCEWithLogitsLoss works with raw logits\n","                   y_train)\n","    acc = accuracy_fn(y_true=y_train,\n","                      y_pred=y_pred)\n","\n","    # 3. Optimizer zero grad\n","    optimizer.zero_grad()\n","\n","    # 4. Loss backwards\n","    loss.backward()\n","\n","    # 5. Optimizer step\n","    optimizer.step()   #update to the model's parameters\n","\n","    ### Testing\n","    model.eval()\n","    with torch.inference_mode():\n","        # 1. Forward pass\n","        test_logits = model(X_test).squeeze()\n","        test_pred = torch.round(torch.sigmoid(test_logits))\n","        # 2. Caculate loss/accuracy\n","        test_loss = loss_fn(test_logits,\n","                            y_test)\n","        test_acc = accuracy_fn(y_true=y_test,\n","                               y_pred=test_pred)\n","\n","    # Print out what's happening every 10 epochs\n","    if epoch % 10 == 0:\n","        print(f\"Epoch: {epoch} |Train Loss: {loss:.5f},Train Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ShxzRFGS5v_C","executionInfo":{"status":"ok","timestamp":1721277082979,"user_tz":-330,"elapsed":16,"user":{"displayName":"Satheesh Palanisamy","userId":"05467039449028314876"}},"outputId":"cc2e14dd-b586-43b2-cdc8-c14f9f6570fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0 |Train Loss: 0.08443,Train Accuracy: 98.02% | Test loss: 0.07708, Test acc: 98.25%\n","Epoch: 10 |Train Loss: 0.07880,Train Accuracy: 98.02% | Test loss: 0.07376, Test acc: 98.25%\n","Epoch: 20 |Train Loss: 0.07410,Train Accuracy: 98.02% | Test loss: 0.07128, Test acc: 98.25%\n","Epoch: 30 |Train Loss: 0.07013,Train Accuracy: 98.24% | Test loss: 0.06930, Test acc: 98.25%\n","Epoch: 40 |Train Loss: 0.06665,Train Accuracy: 98.24% | Test loss: 0.06766, Test acc: 98.25%\n","Epoch: 50 |Train Loss: 0.06361,Train Accuracy: 98.68% | Test loss: 0.06634, Test acc: 98.25%\n","Epoch: 60 |Train Loss: 0.06094,Train Accuracy: 98.68% | Test loss: 0.06527, Test acc: 98.25%\n","Epoch: 70 |Train Loss: 0.05850,Train Accuracy: 98.68% | Test loss: 0.06439, Test acc: 98.25%\n","Epoch: 80 |Train Loss: 0.05628,Train Accuracy: 98.68% | Test loss: 0.06369, Test acc: 98.25%\n","Epoch: 90 |Train Loss: 0.05427,Train Accuracy: 98.68% | Test loss: 0.06312, Test acc: 98.25%\n"]}]},{"cell_type":"markdown","source":["Both The Train accuracy and Test accuracy are good"],"metadata":{"id":"7zyddGv8HI5C"}},{"cell_type":"code","source":["model(X_train).squeeze()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oraoGFq87vHO","executionInfo":{"status":"ok","timestamp":1721276315557,"user_tz":-330,"elapsed":850,"user":{"displayName":"Satheesh Palanisamy","userId":"05467039449028314876"}},"outputId":"7e97dc04-5707-4878-bf41-7254958833ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([  5.3158, -10.7344,   7.2091,   2.8982,   6.1192,  -5.1027,   4.4613,\n","          5.4579,   3.9618,  -4.5581,   1.9404,  -6.2140,  -4.1703,   5.1437,\n","          4.6126,  -7.1758, -10.4688,  -6.7505,   3.2987,   4.4907,   3.4810,\n","         -4.6427,   1.1140,   4.6092,   0.5025,  -3.2754,   4.3190,  -7.6933,\n","          7.0305,   7.1292,  -2.8378,   4.0836,  -5.2456,  -6.3849,  -0.6588,\n","          5.5650,  -1.0916,   6.1837,   8.0237,   2.7645,   4.6398, -14.4808,\n","         -4.8797,   7.3227,   3.3968,   7.1054,   8.3573,   5.7409,   6.7332,\n","          4.1903,  -1.0509,   5.0493,   5.1473,   0.3755,   6.6104,  -3.2829,\n","          3.5319,   4.4305,   4.9575,   0.5100,   4.6615,   2.2167,  -0.9645,\n","          2.2564,   4.5722,   3.0335,   1.5607,   3.2000,   6.1529,  -2.1672,\n","         -4.2838,  -2.3645,  -1.2768,   3.0861,  -2.4808,   4.0537,  -6.6943,\n","          3.7373,   4.1487,   6.8110,   4.5578,  -1.4664,   1.2626,   7.0541,\n","         -7.5703,   6.5084,   4.0146,   6.6044, -10.3889,   4.1726,  -7.2230,\n","         -6.8304,   5.6710,   4.4464,   2.9070,  -1.3485,   6.1002,   6.7430,\n","          4.7929,   7.5624,  -3.6043,   5.3046,   4.6018,   7.3350,   5.9950,\n","          6.3188,  -2.8495,   1.3970,  -7.6791,  -5.6679,   4.0764,   4.8879,\n","         -9.6924,   3.6612,   8.3660,   2.9432,   3.0722,   3.0871,   3.7692,\n","          4.3517,  -0.7813,  -3.5200, -12.1706,   5.6674,   3.9768,  -7.2012,\n","          2.9803,   4.0246,  -3.5770,   4.1210,  -2.0692,   8.7222,  -6.7943,\n","          4.6941,   0.8047,   5.4009,   0.8304,  -1.7220,   4.4698,   6.1644,\n","          3.5388,  -7.4682,   3.6527,  -4.2363,   2.2860,  -4.6989,   4.7514,\n","         -3.1382,   4.9684,   0.8496,  -4.2027,   1.8448,   9.3451,   4.9756,\n","          5.2695,  -2.6904,   1.7438,   5.4305,   3.4450,  -6.7173,   0.1140,\n","          4.7209,  -2.8158,   7.6860,   6.7605,  -7.6536,   4.8061,   5.6638,\n","          4.6334,   4.0629,   4.4130,   1.8556,   6.7319,  -2.9951,   5.3456,\n","          3.6137,   3.2920,  -0.9604,   7.4718,  -5.4787,   0.4418,   2.4472,\n","          5.1293,  -2.1172,   5.5911,  -2.4699,  -6.4061,   8.1639,   3.0139,\n","         -3.2606,   6.2052,  -3.9201,  -1.8645,   3.5626,   2.6650,   4.5461,\n","          2.3405,   0.8914,   3.5552,   8.6447,  -5.3711,   4.5528,  -2.4895,\n","          2.9005,   2.2142,   2.1526, -13.5720,   3.0322, -10.5575,   4.4464,\n","          3.3937,  -6.0431,  -6.1357,   6.4207,   5.0755,  -5.2164,   4.2433,\n","         -5.5286, -13.3283,   6.7644,  -9.9152,  -9.2313,   4.6095,   1.4696,\n","         -4.7072,  -5.3589,  -8.4786,   2.9351,   4.9118,   4.2024,   4.4284,\n","         -3.2134,   4.8812,  -3.8712,  -7.9592,  -6.0171,   0.4027,   7.1567,\n","          4.0255,   1.6407,   1.9649,   2.8584,   3.1075,   5.7072,   2.9649,\n","         -4.2151,  -5.7768,   2.0173,   6.6361,  -5.7215,   5.0674,   4.3667,\n","          8.7562,   5.4374,   6.6195,  -5.4971,   5.4580,   3.3793,  -7.5740,\n","         -3.4775,   4.3099,  -1.3929,   3.4945,  -9.2114,   3.1225,   3.5536,\n","          5.9474,   5.6579,   5.2544,   3.6637,  -4.1412,   6.8054,   2.3752,\n","         -3.0992,   2.9799,   5.7524,   5.9301,   6.2277,   4.1982,   1.6691,\n","         -7.3600,   1.6019,   2.2933,  -1.0838,   2.5742,  -2.9033,  -2.9225,\n","         -4.4900,   2.8310,  -2.2529,   3.0021,   7.2801,  -5.8271,  -4.8727,\n","         -6.0087,   5.2241,   4.1175,   3.8364,   4.3609,   1.7406,   3.5215,\n","          4.2775,  -5.9347,   4.4382,   3.9943,   1.9137,  -5.7552,   6.3063,\n","          5.2337,  -3.3779,  -0.2057,   7.0769,  -4.2840,   5.8966,  -5.2033,\n","         -5.5454,   7.4238,   4.7473,  -5.7547,   3.6259,  -4.3712,  -8.5289,\n","          4.9254,  -4.7954,  -0.8400,   6.4965,   1.3938,  -0.9175,   5.3883,\n","         -0.1074,   5.6101,   3.6283,  -1.0028,   5.8935,   1.8540,  -2.5456,\n","         -5.7852,  -7.6263,   2.8879,   6.3225,   2.3285,  -4.1583,  -3.9510,\n","          4.9996,  -4.4074,  -5.9591,   3.8984,   4.7718,   5.3979,  -7.9275,\n","          7.5906,  -4.1794,  -4.5872,  -5.0784,   2.0573,   0.4454,   2.4728,\n","         -4.1220,   4.9191,   4.6203,  -3.0780,  -8.0998,  -4.1773,  -4.6502,\n","          1.6733,  -4.5988,   4.6560,   7.2516,   3.1154,   2.8027,   3.2107,\n","          5.4502,   5.8199,  -6.3567, -11.3741,  -1.7385, -15.4962,   5.2664,\n","          1.1854,   4.8248,   0.5834, -20.5421,   1.0146,  -2.3477,   5.7786,\n","          6.1705,   4.8429,   3.2676,   2.2542,  -3.2823,  -4.4501,  -2.1733,\n","          6.0629,   5.8090,  -5.1082,   0.7487,   6.0186,  -5.9165,  -2.3172,\n","         -3.9672,  -3.7987,   5.2704,   3.2722,   0.1445,  -4.1872,   1.9317,\n","          3.5257,   4.1540,  -7.6656,  -0.6314, -10.2670,   7.3192,   6.3261,\n","         -0.9990,   6.7215,   5.2015,   6.6145,   8.2601,  -9.8116,   2.1884,\n","          2.6355,   4.9237,   2.8774,   6.0133,   4.4102,   5.9312,   5.2272,\n","          5.4799,  -8.1602,   7.3628,   7.4973,   4.7794,   2.7585,   6.9406,\n","          3.2711,  -0.1180,  -0.5413,   1.3872,  -6.1542,   6.7113,   4.5150,\n","         -0.5270,  -3.7311,  -5.6286,   3.0693,  -2.3240,  -3.9788,   1.7469,\n","         -4.0324,   3.6128,   9.9784,   2.2300,   5.7397,  -1.8592,   3.7680],\n","       device='cuda:0', grad_fn=<SqueezeBackward0>)"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":[" Remove Extra Dimension: Sometimes, the model's output has an extra dimension of size 1 that we don't need. .squeeze() removes this unnecessary dimension to match the expected shape of the labels."],"metadata":{"id":"ipEga_BPEEUo"}},{"cell_type":"markdown","source":["Making a Predictive System"],"metadata":{"id":"czQ3vtmyH8fT"}},{"cell_type":"code","source":["\n","y_pred_labels = torch.round(torch.sigmoid(model(X_test.to(device))[:10]))\n","y_preds.squeeze()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"idJJQX9AJ1yH","executionInfo":{"status":"ok","timestamp":1721277978235,"user_tz":-330,"elapsed":992,"user":{"displayName":"Satheesh Palanisamy","userId":"05467039449028314876"}},"outputId":"bcd9dbba-4e3e-4111-835a-e491a1eb1ee6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 1.], device='cuda:0',\n","       grad_fn=<SqueezeBackward0>)"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["If y_pred_probs >= 0.5, y=1 (class 1)\n","\n","If y_pred_probs < 0.5, y=0 (class 0)"],"metadata":{"id":"H2YirbKjKu-X"}},{"cell_type":"code","source":["y_test[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w2fhvYF-KDuf","executionInfo":{"status":"ok","timestamp":1721277899450,"user_tz":-330,"elapsed":1026,"user":{"displayName":"Satheesh Palanisamy","userId":"05467039449028314876"}},"outputId":"ed73d4ae-e161-4f48-fd64-e8b00193dc83"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 0., 0., 1., 1., 0., 0., 0., 1., 1.], device='cuda:0')"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["Now it looks like our model's predictions are in the same form as our truth labels (y_test)."],"metadata":{"id":"b-MosYDBKpr5"}},{"cell_type":"code","source":[],"metadata":{"id":"lNR4wKRFKrEI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Conclusion:\n","\n","Building a neural network for breast cancer prediction using deep learning involves carefully training and evaluating the model. In our implementation, we achieved a training accuracy of 98.68% and a test accuracy of  98.25%, demonstrating the model's capability to generalize well to unseen data. This indicates that our model can effectively predict breast cancer cases based on the given dataset."],"metadata":{"id":"ry1M6-uwLMlC"}}]}